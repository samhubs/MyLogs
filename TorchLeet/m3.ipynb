{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the accuracy of a vanila CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchvision.transforms as v2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vanilla CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Output: 32x32x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vanilla CNN Model\n",
    "class CNNModelWeightInit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Output: 32x32x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.modules:\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, epochs=5, scheduler=None):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "        for images, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            print(f\"scheduler update\")\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "def testing_loop(model):\n",
    "    # Evaluate on the test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [00:49<03:18, 49.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [01:37<02:25, 48.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [02:28<01:39, 49.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.3499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [03:21<00:50, 50.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 1.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [04:08<00:00, 49.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.7273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.92%\n"
     ]
    }
   ],
   "source": [
    "# Vanilla model\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "training_loop(model, criterion, optimizer)\n",
    "accuracy = testing_loop(model)\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporating BatchNorm, Dropout\n",
    "class CNNModel_BN_DO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [00:52<07:55, 52.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [01:46<07:05, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 1.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [02:39<06:13, 53.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 1.3777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [03:33<05:20, 53.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 1.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [04:26<04:26, 53.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 1.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [05:19<03:33, 53.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 1.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [06:12<02:39, 53.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 1.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [07:05<01:46, 53.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 1.3360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [07:58<00:52, 52.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 1.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [08:48<00:00, 52.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.8911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 54.86%\n"
     ]
    }
   ],
   "source": [
    "# CNN with BatchNorm and Dropout\n",
    "model_BN_DO = CNNModel_BN_DO()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_BN_DO.parameters(), lr=0.001)\n",
    "training_loop(model_BN_DO, criterion, optimizer, epochs=10)\n",
    "accuracy = testing_loop(model_BN_DO)\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporating BatchNorm, Dropout with weight initialization and a lr scheduler\n",
    "class CNNModel_BN_DO_weightInitScheduler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                init.xavier_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [00:58<08:47, 58.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [1/10], Loss: 1.2726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [01:59<07:57, 59.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [2/10], Loss: 1.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [02:59<07:01, 60.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [3/10], Loss: 1.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [03:57<05:56, 59.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [4/10], Loss: 1.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [04:54<04:51, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [5/10], Loss: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [05:51<03:51, 57.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [6/10], Loss: 0.9979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [06:47<02:52, 57.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [7/10], Loss: 1.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [07:44<01:54, 57.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [8/10], Loss: 1.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [08:40<00:56, 56.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [9/10], Loss: 1.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [09:40<00:00, 58.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [10/10], Loss: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.1%\n"
     ]
    }
   ],
   "source": [
    "# Model with BatchNorm and Dropout but with weight initialization and a scheduler\n",
    "# CNN with BatchNorm and Dropout\n",
    "model_BN_DO_weightInitScheduler = CNNModel_BN_DO_weightInitScheduler()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_BN_DO_weightInitScheduler.parameters(), lr=0.001)  \n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "training_loop(model_BN_DO_weightInitScheduler, criterion, optimizer, epochs=10, scheduler=scheduler)\n",
    "accuracy = testing_loop(model_BN_DO_weightInitScheduler)\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 1/5 [03:46<15:04, 226.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 2/5 [07:32<11:19, 226.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 3/5 [11:21<07:35, 227.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 4/5 [15:12<03:48, 228.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 5/5 [19:01<00:00, 228.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.7127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.98\n"
     ]
    }
   ],
   "source": [
    "# Inbuilt deeper model\n",
    "model_resnet = torchvision.models.resnet18()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=0.01)\n",
    "training_loop(model_resnet, criterion, optimizer)\n",
    "print(f\"Accuracy: {testing_loop(model_resnet)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporating BatchNorm, Dropout with weight initialization and a lr scheduler\n",
    "class CNNModel_BN_DO_weightInitScheduler_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        # self.relu2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 256, 16, 16\n",
    "        self.fc1 = nn.Linear(256*16*16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        # self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.Linear):\n",
    "                init.xavier_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module.bias, 0)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  10%|█         | 1/10 [06:53<1:01:59, 413.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [1/10], Loss: 1.5152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  20%|██        | 2/10 [13:45<54:59, 412.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [2/10], Loss: 1.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  30%|███       | 3/10 [19:48<45:30, 390.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [3/10], Loss: 0.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  40%|████      | 4/10 [25:17<36:36, 366.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [4/10], Loss: 0.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  50%|█████     | 5/10 [30:44<29:19, 351.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [5/10], Loss: 1.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  60%|██████    | 6/10 [36:15<22:59, 344.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [6/10], Loss: 0.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  70%|███████   | 7/10 [42:27<17:41, 353.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [7/10], Loss: 1.0814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  80%|████████  | 8/10 [49:05<12:15, 367.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [8/10], Loss: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:  90%|█████████ | 9/10 [55:51<06:19, 379.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [9/10], Loss: 0.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 10/10 [1:02:33<00:00, 375.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler update\n",
      "Epoch [10/10], Loss: 0.2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.71%\n"
     ]
    }
   ],
   "source": [
    "# Model with BatchNorm, Dropout, weight initialization,a scheduler and additional FC layer\n",
    "model_BN_DO_weightInitScheduler_2 = CNNModel_BN_DO_weightInitScheduler_2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_BN_DO_weightInitScheduler_2.parameters(), lr=0.001)  \n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "training_loop(model_BN_DO_weightInitScheduler_2, criterion, optimizer, epochs=10, scheduler=scheduler)\n",
    "accuracy = testing_loop(model_BN_DO_weightInitScheduler_2)\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.5%\n"
     ]
    }
   ],
   "source": [
    "accuracy = testing_loop(model_BN_DO_weightInitScheduler_2)\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylogs--5zRa99S-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
